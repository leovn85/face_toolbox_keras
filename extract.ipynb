{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/shaoanlu/face_toolbox_keras.git\n!pip uninstall -y tensorflow\n!pip install tensorflow-gpu==1.13.1\n!pip install keras==2.2.4\n%cd face_toolbox_keras\n\n!gdown https://drive.google.com/uc?id=1H37LER8mRRI4q_nxpS3uQz3DcGHkTrNU\n!mv lresnet100e_ir_keras.h5 ./models/verifier/insightface/lresnet100e_ir_keras.h5\n!gdown https://drive.google.com/uc?id=18MyyXQIwhR5I6gzipYMiJ9ywgvFWQMvI\n!mv backbone_ir50_ms1m_keras.h5 ./models/verifier/face_evoLVe_ir50/backbone_ir50_ms1m_keras.h5\n!gdown https://drive.google.com/uc?id=1P_eQHU8bNJEsB6hHt_fnltOwQVKIfhiX\n!mv backbone_ir50_asia_keras.h5 ./models/verifier/face_evoLVe_ir50/backbone_ir50_asia_keras.h5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nimport cv2\nimport numpy as np\nimport math\nimport os\nimport imageio\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nfrom skimage import transform as trans\nfrom models.detector import face_detector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\nfd = face_detector.FaceAlignmentDetector(\n    lmd_weights_path=\"./models/detector/FAN/2DFAN-4_keras.h5\"# 2DFAN-4_keras.h5, 2DFAN-1_keras.h5\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageClass():\n    \"Stores the paths to images for a given class\"\n    def __init__(self, name, image_paths):\n        self.name = name\n        self.image_paths = image_paths\n  \n    def __str__(self):\n        return self.name + ', ' + str(len(self.image_paths)) + ' images'\n  \n    def __len__(self):\n        return len(self.image_paths)\n\ndef get_dataset(path, has_class_directories=True):\n    dataset = []\n    path_exp = os.path.expanduser(path)\n    classes = [path for path in os.listdir(path_exp) \\\n                    if os.path.isdir(os.path.join(path_exp, path))]\n    classes.sort()\n    nrof_classes = len(classes)\n    for i in range(nrof_classes):\n        class_name = classes[i]\n        facedir = os.path.join(path_exp, class_name)\n        image_paths = get_image_paths(facedir)\n        dataset.append(ImageClass(class_name, image_paths))\n  \n    return dataset\n\ndef get_image_paths(facedir):\n    image_paths = []\n    if os.path.isdir(facedir):\n        images = os.listdir(facedir)\n        image_paths = [os.path.join(facedir,img) for img in images]\n    return image_paths\n\ndef to_rgb(img):\n    w, h = img.shape\n    ret = np.empty((w, h, 3), dtype=np.uint8)\n    ret[:, :, 0] = ret[:, :, 1] = ret[:, :, 2] = img\n    return ret\n\ndef draw_bounding_boxes(image, bboxes, color=(255, 0, 0), stroke = 4):\n    for bbox in bboxes:\n      image = cv2.rectangle(image.copy(), (int(bbox[1]), int(bbox[0])), (int(bbox[3]), int(bbox[2])), color, stroke)\n    return image\n\ndef ScaleRotateTranslate(image, angle, center = None, new_center = None, scale = None, resample=Image.BICUBIC):\n    #image = Image.fromarray(image)\n    angle = math.radians(angle) #convert from degree to radians\n    if (scale is None) and (center is None):\n        return image.rotate(angle=angle, resample=resample)\n    nx,ny = x,y = center\n    sx=sy=1.0\n    if new_center:\n        (nx,ny) = new_center\n    if scale:\n        (sx,sy) = (scale, scale)\n    \n    cosine = math.cos(angle)\n    sine = math.sin(angle)\n\n    a = cosine/sx\n    b = sine/sx\n    c = x-nx*a-ny*b\n    d = -sine/sy\n    e = cosine/sy\n    f = y-nx*d-ny*e\n    \n    return image.transform(image.size, Image.AFFINE, (a,b,c,d,e,f), resample=resample)\n\ndef center_crop(img, bbox, new_width=None, new_height=None):        \n    \n\n    if new_width is None:\n      new_width = min(width, height)\n\n    if new_height is None:\n      new_height = min(width, height)\n      \n    newx1, newx2, newy1, newy2 = bbox[1], bbox[3], bbox[0], bbox[2]\n    if (new_width < new_height):\n      newx1 = bbox[1] - int(np.ceil((new_height - new_width) / 2))\n      newx2 = bbox[3] + int(np.ceil((new_height - new_width) / 2))\n      if (newx1 < 0):\n        temp1 = newx1\n        newx1 = 0\n        newx2 += temp1\n    if (new_height < new_width):\n      newy1 = bbox[0] - int(np.ceil((new_width - new_height) / 2))\n      newy2 = bbox[2] + int(np.ceil((new_width - new_height) / 2))\n      if (newy1 < 0):\n        temp2 = newy1\n        newy1 = 0\n        newy2 += temp2\n    center_cropped_img = img.crop((newx1, newy1, newx2, newy2))\n\n    return center_cropped_img\n\ndef CropResizePIL(image, bbox, scale = None, resample=Image.LANCZOS):\n    image = Image.fromarray(image)\n    w, h = image.size\n    w1, h1 = (bbox[3]-bbox[1], bbox[2] - bbox[0])\n    if (scale is None):\n      scale = (w, h)\n    img = center_crop(image, bbox, w1, h1)\n    #scaleX = scale[0] / w\n    #scaleY = scale[1] / h\n    #sy, sy = (scaleX, scaleY)\n    #img = image.crop((bbox[1], bbox[0], bbox[3], bbox[2]))\n    img = img.resize(scale, resample=resample)\n    return img\ndef convert_landmarks_68_to_5_array(landmarks):\n        left_eye = np.mean(landmarks[36:42], axis=0)\n        right_eye = np.mean(landmarks[42:48], axis=0)\n        nose_tip = landmarks[30]\n        left_mouth = landmarks[48]\n        right_mouth = landmarks[54]\n        new_landmarks = [\n            left_eye[0], left_eye[1],\n            right_eye[0], right_eye[1],\n            nose_tip[0], nose_tip[1],\n            left_mouth[0], left_mouth[1] ,\n            right_mouth[0], right_mouth[1]]\n        return new_landmarks    \ndef make_landmarks_68_to_5(landmarks):\n  new_landmarks = []\n  for landmark in landmarks:\n    new_landmark = convert_landmarks_68_to_5_array(landmark)\n    #for item in new_landmark:\n    new_landmarks.append(new_landmark)\n  #new_landmarks = new_landmarks.flatten()\n  #new_landmarks = np.array(new_landmarks)\n  return new_landmarks\n\ndef rotateImage(img, landmark):\n  eye_left = (landmark[0], landmark[1])\n  eye_right = (landmark[2], landmark[3])\n  dY = eye_right[1] - eye_left[1]\n  dX = eye_right[0] - eye_left[0]\n  angle = np.degrees(np.arctan2(dY, dX)) - 90\n  #print(f\"angle: {angle}\")\n  #test_image = Image.open(\"images/8.jpg\")\n  image_center = ((eye_left[0]+eye_right[0])/2,(eye_left[1]+eye_right[1])/2)\n  imgCopy = Image.fromarray(img)\n  rotatedImg = ScaleRotateTranslate(imgCopy,center=image_center,angle=angle)\n  return rotatedImg\n  \ndef isLeftEyeAndRightEyeOnSameLine(left_eye, right_eye):\n    if (int(left_eye[0]) == int(right_eye[0])):\n        return True\n    return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output_dir = \"/content/aligned/\"\ninput_dir = \"/content/train/\"\nif not os.path.exists(output_dir):\n\tos.makedirs(output_dir)\n    \ndataset = get_dataset(input_dir)\n\nnrof_images_total = 0\nnrof_successfully_aligned = 0\nfor cls in dataset:\n    output_class_dir = os.path.join(output_dir, cls.name)\n    if not os.path.exists(output_class_dir):\n        os.makedirs(output_class_dir)\n    for image_path in cls.image_paths:\n        nrof_images_total += 1\n        filename = os.path.splitext(os.path.split(image_path)[1])[0]\n        output_filename = os.path.join(output_class_dir, filename+'.png')\n        print(image_path)\n        if not os.path.exists(output_filename):\n            try:\n                img = imageio.imread(image_path)\n            except (IOError, ValueError, IndexError) as e:\n                errorMessage = '{}: {}'.format(image_path, e)\n                print(errorMessage)\n            else:\n                if img.ndim<2:\n                    print('Unable to align \"%s\"' % image_path)\n                    text_file.write('%s\\n' % (output_filename))\n                    continue\n                if img.ndim == 2:\n                    img = to_rgb(img)\n                img = img[:,:,0:3]\n\n                bounding_boxes_class, landmark_points = fd.detect_face(img, with_landmarks=True)\n                \n                bounding_boxes = np.array(bounding_boxes_class)\n                points = np.array(make_landmarks_68_to_5(landmark_points))\n                #print(points)\n                nrof_faces = bounding_boxes.shape[0]\n                if nrof_faces>0:\n                    det = bounding_boxes[:,0:4]\n                    det_points = points\n                    #print(det_points)\n                    det_arr = []\n                    det_points_arr = []\n                    img_size = np.asarray(img.shape)[0:2]\n                    if nrof_faces>1:\n                        for i in range(nrof_faces):\n                                det_arr.append(np.squeeze(det[i]))\n                                det_points_arr.append(np.squeeze(det_points[i]))\n                    else:\n                        det_arr.append(np.squeeze(det))\n                        det_points_arr.append(np.squeeze(det_points))\n                    '''print(f\"det_points arr: {det_points_arr}\")\n                    print(f\"det arr: {det_arr}\")\n                    input(f\"Press any key to continue\")'''\n                    #for i, det in enumerate(det_arr):\n                    ii = 0\n                    for det, det_point in zip(det_arr, det_points_arr):\n                        det = np.squeeze(det)\n                        #print(det_point)\n                        det_point = np.squeeze(det_point)\n                        '''print(f\"det_point: {det_point}\")\n                        print(f\"det: {det}\")\n                        input(f\"Press any key to continue\")'''\n                        bb = np.zeros(4, dtype=np.int32)\n                        margin = 20\n                        bb[0] = np.maximum(det[0]-margin/2, 0)\n                        bb[1] = np.maximum(det[1]-margin/2, 0)\n                        bb[2] = np.minimum(det[2]+margin/2, img_size[1])\n                        bb[3] = np.minimum(det[3]+margin/2, img_size[0])\n                        \n                        bbox = np.array([bb[0], bb[1], bb[0]+bb[2], bb[1]+bb[3]])\n                        #print(bbox)\n                        #print(det_point)\n                        landmark = np.array([det_point[0], det_point[1], det_point[2], det_point[3], det_point[4],\n                                            det_point[5], det_point[6], det_point[7], det_point[8], det_point[9]])\n                        #rotate image depends on eye center, then detect face on new image and crop + resize\n                        print(landmark)\n                        image_ii = rotateImage(img, landmark)\n                        newImg = np.array(image_ii)\n                        new_bboxes, new_landmarks = fd.detect_face(newImg, with_landmarks=True)\n                        landmarks = np.array(make_landmarks_68_to_5(new_landmarks))\n                        t = 0\n                        for landmark_i in landmarks:\n                            l_eye = (landmark_i[0], landmark_i[1])\n                            r_eye = (landmark_i[2], landmark_i[3])\n                            if isLeftEyeAndRightEyeOnSameLine(l_eye, r_eye):\n                                ii = t    \n                                break\n                            t += 1\n                            \n                        new_bbox = new_bboxes[ii]\n                        \n                        imageFinal = CropResizePIL(newImg, new_bbox, scale=(112, 112))\n                        nimg = np.array(imageFinal)\n                        '''landmarks = np.array([landmarks[\"left_eye\"][0], landmarks[\"right_eye\"][0], landmarks[\"nose\"][0], landmarks[\"mouth_left\"][0], landmarks[\"mouth_right\"][0],\n                         landmarks[\"left_eye\"][1], landmarks[\"right_eye\"][1], landmarks[\"nose\"][1], landmarks[\"mouth_left\"][1], landmarks[\"mouth_right\"][1]])'''\n                        #landmarks = landmarks.reshape((2,5)).T\n                        #print(landmarks)\n                        #nimg = face_preprocess.preprocess(img, bbox, landmarks, image_size=f'{args.image_size},{args.image_size}')\n                        #cv2.imshow(\"test\", cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR))\n                        #cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n                        #scaled = skimage.transform.resize(cropped, (args.image_size, args.image_size))\n                        nrof_successfully_aligned += 1\n                        filename_base, file_extension = os.path.splitext(output_filename)\n                        output_filename_n = \"{}_{}{}\".format(filename_base, ii, file_extension)\n                           \n                        #scaled = img_as_ubyte(scaled)\n                        #imageio.imwrite(output_filename_n, scaled)\n                        imageio.imwrite(output_filename_n, nimg)\n                        #text_file.write('%s %d %d %d %d\\n' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\n                        ii += 1\n                        #cv2.waitKey(0)\n                        #cv2.destroyAllWindows()\n                else:\n                    print('Unable to align \"%s\"' % image_path)\n                    text_file.write('%s\\n' % (output_filename))\n\t\t\t\t\t\t\nprint('Total number of images: %d' % nrof_images_total)\nprint('Number of successfully aligned images: %d' % nrof_successfully_aligned)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}